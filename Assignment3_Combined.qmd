---
title: "Assignment3: Supervised Learning Competition - Group 11"
authors: 
  - Lourenço Santos Moitinho de Almeida
  - Liam Thomassen
  - Tim Rentenaar
  - Erdem Koçer 
date: last-modified
format:
  html:
    toc: true
    self-contained: true
    code-fold: true
    df-print: kable
---

```{r}
#| label: R packages
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(fastDummies)
library(ISLR)
library(keras)
library(corrplot)
library( ggplot2 )  
library(dplyr)
```

```{r}
#| label: Data loading
#| echo: false
test_data <- readRDS("test.rds")
train_data <-readRDS("train.rds")
```

## Data Description & Data Exploration

In order to predict student performance using the various characteristics of the students, we begin our analysis by exploring our dataset. Our exploratory data analysis will roughly follow the guidelines stated by Tukey and Peng. With that said, in order to get a preliminary understanding of our data, we ran the `str()` command as shown below in *Table 1*:

**Table 1:** Checking the Packaging of the Dataset using `str()`

```{r}
#| label: Checking Packaging 
str(train_data)
```

```{r}
#| label: Splitting the training dataset into variable types 
factor_cols <- names(train_data)[sapply(train_data, is.factor)]
num_cols <- names(train_data)[sapply(train_data, is.numeric)]
```

This training dataset contains `r nrow(train_data)` rows and `r ncol(train_data)` columns. Furthermore, the column `score` represents our dependent variable while the rest of the columns are explanatory variables. This dataset contains two types of variables: factor (categorial) and numerical variables. Each column can be categorized into one of the two variables types:

-   <u>Factor Variables:</u> `r paste(factor_cols, collapse=", ")`
-   <u>Numerical Variables:</u> `r paste(num_cols, collapse=", ")`

Additionally, *Figure 1* dispalys that this dataset doesn't contain any missing values. Therefore, any missing information imputation strategies won't be required during the data (pre)processing step of our analysis.

**Figure 1:** Counts of all the Missing Data per Column

```{r}
#| label: Missing data counts per column 
sapply(train_data, function(x) sum(is.na(x)))
```

An important thing to note is that despite the insights given by running the `str()` command, reading the column descriptions file gives contradicting information. For instance out of the `r sum(sapply(train_data, is.numeric))` numeric columns, only `age`, `absences` and `score` are 'true' numericcal variables. The rest of the variables are ordinal variables such as `Dalc`, a variable ranging from 1-5 based on workday alcohol consumption. This assessment is further backed up by analysing the top and bottom of the dataset as shown below in *Table 2* and *Table 3*:

**Table 2:** Top of the Dataset

```{r}
#| label: Top of the Dataset 
head(train_data)
```

**Table 3:** Bottom of the Dataset

```{r}
#| label: Bottom of the Dataset 
tail(train_data)
```

### The Analysis for the Dependent Variable: Score

```{r}
#| label: 5-number summary for score
minimum_value <- round(min(train_data$score), 2)
maximum_value <- round(max(train_data$score), 2)
median_value <- round(median(train_data$score), 2)
q1_value <- round(quantile(train_data$score, 0.25), 2)
q3_value <- round(quantile(train_data$score, 0.75), 2)
```

The whole aim of this analysis is to predict scores for students in the test dataset. In order to do so we took a closer look at the variable `score`. Below, *Figure 2* displays the spread of `score` in addition to a 5-number summary. Following the inter-quartile range rule for outlier detection, scores outside the range of $`r q1_value-1.5*(q3_value-q1_value)`\leq x \leq `r q3_value+1.5*(q3_value-q1_value)`$ would be considered outliers.

**Figure 2:** The Spread and 5-Number Summary of `score`

```{r}
#| label: Spread and summary statistics of score
# I made 3 graphs. Either pick one or multiple or make a new one!!!
train_data |> ggplot(aes(x=score)) +
  geom_histogram(fill = "skyblue", breaks = pretty(train_data$score, n=50)) + 
  geom_vline(xintercept = minimum_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Minimum =", minimum_value), color = "black", angle = 90, x = minimum_value-0.1, y = 19, size = 3) +
  geom_vline(xintercept = maximum_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Maximum =", maximum_value), color = "black", angle = 90, x = maximum_value-0.1, y = 19, size = 3) +
  geom_vline(xintercept = median_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Median =", median_value), color = "black", angle = 90, x = median_value-0.1, y = 19, size = 3) +
  geom_vline(xintercept = q1_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Quartile 1 =", q1_value), color = "black", angle = 90, x = q1_value-0.1, y = 19, size = 3) +
  geom_vline(xintercept = q3_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Quartile 3 =", q3_value), color = "black", angle = 90, x = q3_value-0.1, y = 19, size = 3) 
```

```{r}
ggplot(train_data, aes(x = score)) +
  geom_density(fill = "skyblue") +
  xlab("Scores") +
  ylab("Frequency") +
  ggtitle("Density Plot of Scores with 5-Number Summary Overlay") +
  theme(plot.title = element_text(hjust = 0.5)) +
  
  geom_vline(aes(xintercept = minimum_value, color = "Minimum"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Minimum =", minimum_value), color = "black", angle = 90, x = minimum_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = maximum_value, color = "Maximum"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Maximum =", maximum_value), color = "black", angle = 90, x = maximum_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = median_value, color = "Median"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Median =", median_value), color = "black", angle = 90, x = median_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = q1_value, color = "Quartile 1"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Quartile 1 =", q1_value), color = "black", angle = 90, x = q1_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = q3_value, color = "Quartile 3"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Quartile 3 =", q3_value), color = "black", angle = 90, x = q3_value-0.1, y = 0.2, size = 3)
  

```

```{r}
ggplot(train_data, aes(x = score)) +
  geom_density(fill = "skyblue") +
  xlab("Scores") +
  ylab("Frequency") +
  ggtitle("Density Plot of Scores with 5-Number Summary Overlay") +
  theme(plot.title = element_text(hjust = 0.5)) +
  
  geom_vline(aes(xintercept = minimum_value, color = "Minimum = -2.71"), linetype = "longdash") + 
  annotate(geom = "text", label = "Minimum", color = "black", angle = 90, x = minimum_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = maximum_value, color = "Maximum = 2.23"), linetype = "longdash") + 
  annotate(geom = "text", label = "Maximum", color = "black", angle = 90, x = maximum_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = median_value, color = "Median = -0.03"), linetype = "longdash") + 
  annotate(geom = "text", label = "Median", color = "black", angle = 90, x = median_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = q1_value, color = "Quartile 1 = -0.63"), linetype = "longdash") + 
  annotate(geom = "text", label = "Quartile 1", color = "black", angle = 90, x = q1_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = q3_value, color = "Quartile 3 = 0.64"), linetype = "longdash") + 
  annotate(geom = "text", label = "Quartile 3", color = "black", angle = 90, x = q3_value-0.1, y = 0.2, size = 3) +
  
  scale_color_manual("5-Number Summary", values = c("Minimum = -2.71" = "black", "Maximum = 2.23" = "black", "Median = -0.03" = "black", "Quartile 1 = -0.63" = "black", "Quartile 3 = 0.64" = "black"))

```

### Correlation between Score and the Explanatory Variables

For the correlation between `score` and the rest of the explanatory variables we divided the training dataset by variable type. *Table 4* displays the correlation between the numerical variables. The variables `failures`, `goout` and `age` measuring the student's number of past class failures, time spent with friend and age seemed to have the greatest negative correlation against `score` while `Medu` and `Fedu`, variables measuring their parent's education seemed to have the greatest positive correlation. Additionally, `goout` and `Dalc` (workday alcohol consumption) are both positively correlated with `Walc` (weekend alcohol consumption). In contrast, *Table 5* displays the correlation between the converted dummy categorical variables and `score`. Although, none of the categorical variables seemed to be correlated with `score`. The only strongly correlated variables in this table were between the categories of `Mjob` and `Fjob` (variables that measure the parent's occupation).

**Note:** Do we remove the correlated variables for the analysis and models?

**Table 4:** Correlation Matrix between Numerical Variables and `score`

```{r}
#| label: Correlation between numerical variables and score
corrplot(cor(train_data[sapply(train_data, is.numeric)]), diag = FALSE)
```

**Table 5:** Correlation Matrix between Converted Categorical Variables and `score`

```{r}
#| label: Correlation between dummy categorical variables and score
temp_df <- train_data[, !sapply(train_data, is.numeric)]
temp_df_dummy <- dummy_cols(temp_df,remove_first_dummy=TRUE,remove_selected_columns=TRUE)
temp_df_dummy$score <- train_data$score

corrplot(cor(temp_df_dummy), diag = FALSE)
```

## Model Description

1.  Linear Regression
2.  Regularized Regression

-   use lasso, ridge or something better

3.  Some tree-based model

-   e.g. random forest

4.  Attempt Neural Network

## Data Preprocessing & Transformation

-   forward and backward feature selection for regression?

1.  Convert variables into correct data types
2.  Find statistically significant independent variables
3.  One-hot encoding for categorial variables (ordinal encoding for ordinal variables?)
4.  Data Reduction

-   dimensionality reduction
-   remove correlated variables

5.  Some type of scaling for `score`?

-   z-score/min-max

```{r}
train_data_dummy <- dummy_cols(train_data,remove_first_dummy=TRUE,remove_selected_columns=TRUE)
#train_data_dummy
```

```{r}
set.seed(1)

#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(train_data_dummy), replace=TRUE, prob=c(0.9,0.1))
train  <- train_data_dummy[sample, ]
test   <- train_data_dummy[!sample, ]

```

```{r}
X_train <- train[, -which(names(train) == "score")]
y_train <- data.frame(train$score)
```

```{r}
X_test <- test[, -which(names(train) == "score")]
y_test <- test$score
```

```{r}
predict_linreg = lm(score~.,data=train)
#summary(predict_linreg)
y_pred_lin_reg <- predict(predict_linreg,newdata=test)

# Calculate the Mean Squared Error (MSE)
mean((y_pred_lin_reg - y_test)^2)
```

```{r, include = FALSE}
# remove `include = FALSE` later
multinom <- keras_model_sequential() %>%
    layer_dense(16, activation = 'relu') %>%
    layer_dense(12, activation = 'relu') %>%
    layer_dense(1)

multinom %>% compile(
  loss = 'mean_absolute_error',
  optimizer = optimizer_adam(0.001)
)

```

```{r, include = FALSE}
# remove `include = FALSE` later
pl <- multinom %>% fit(as.matrix(X_train), 
      as.matrix(y_train), 
      epochs = 100, 
      validation_split = 0.1,       
      verbose = 1)

```

## Model Comparison

1.  Models 1.1 Linear Regression 1.2 Ridge Regression 1.3 Tree 1.4 Neural Network
2.  Comparison

-   MSE, Train-Val-Test Split (lab 12), Neural Networks have their own special evaluation, ROC curve, AUC

```{r}
# creating a mean trivial baseline is not possible with the caret package 
# the mean trivial baseline will be created with a single train/dev split

sample_size <- floor(0.8 * nrow(train_data_dummy))

set.seed(1234) 

train_index <- sample(seq_len(nrow(train_data_dummy)), size=sample_size)

train_dummy_train <- train_data_dummy[train_index,] 

train_dummy_dev <- train_data_dummy[-train_index,]

mean_score_train <- mean(train_dummy_train$score)

```

```{r}
# resulting Mean Absolute Error from the mean trivial baseline
abserror <- abs(train_dummy_dev$score - mean_score_train)
mae <- mean(abserror)
print(mae)
```

```{r, include = FALSE}
# remove `include = FALSE` later
y_pred <- predict(multinom, as.matrix(X_train))

# Calculate the Mean Squared Error (MSE)
mean((as.matrix(y_train) - y_pred)^2)
```

```{r, include = FALSE}
# remove `include = FALSE` later
y_pred <- predict(multinom, as.matrix(X_test))
# Calculate the Mean Squared Error (MSE)
mean((y_pred - y_test)^2)
```

```{r, include = FALSE}
# remove `include = FALSE` later
ggplot(data=NULL, aes(x=y_test,y=y_pred)) +
  geom_point()+
  geom_abline(intercept = 0, slope = 1, color = "blue") +
  labs(x = "Observed", y = "Predicted") +
  ggtitle("Observed vs. Predicted") +
  xlim(c(-2,2)) +
  ylim(c(-2,2))
```

```{r}
ggplot(data=NULL, aes(x=y_test,y=y_pred_lin_reg)) +
  geom_point()+
  geom_abline(intercept = 0, slope = 1, color = "blue") +
  labs(x = "Observed", y = "Predicted") +
  ggtitle("Observed vs. Predicted") +
  xlim(c(-2,2)) +
  ylim(c(-2,2))
```

## Chosen Model

-   focus on MSE

## Team Member Contributions

-   Lourenço Santos Moitinho de Almeida: a, b, c
-   Liam Thomassen: b, c, d
-   Tim Rentenaar: a, b, d
-   Erdem Koçer: a, b, d
