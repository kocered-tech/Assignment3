---
title: "Assignment3: Supervised Learning Competition - Group 11"
authors: 
  - Lourenço Santos Moitinho de Almeida
  - Liam Thomassen
  - Tim Rentenaar
  - Erdem Koçer 
date: last-modified
format:
  html:
    toc: true
    self-contained: true
    code-fold: true
    df-print: kable
---

```{r}
#| label: R packages
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(fastDummies)
library(ISLR)
#library(keras)
library(corrplot)
library( ggplot2 )  
library(dplyr)
library(caret)
```

```{r}
#| label: Data loading
#| echo: false
test_data <- readRDS("test.rds")
train_data <-readRDS("train.rds")
```

## Data Description & Data Exploration

In order to predict student performance using the various characteristics of the students, we begin our analysis by exploring our dataset. Our exploratory data analysis will roughly follow the guidelines stated by Tukey and Peng. With that said, in order to get a preliminary understanding of our data, we ran the `str()` command as shown below in *Table 1*:

**Table 1:** Checking the Packaging of the Dataset using `str()`

```{r}
#| label: Checking Packaging 
str(train_data)
```

```{r}
#| label: Splitting the training dataset into variable types 
factor_cols <- names(train_data)[sapply(train_data, is.factor)]
num_cols <- names(train_data)[sapply(train_data, is.numeric)]
```

This training dataset contains `r nrow(train_data)` rows and `r ncol(train_data)` columns. Furthermore, the column `score` represents our dependent variable while the rest of the columns are explanatory variables. This dataset contains two types of variables: factor (categorial) and numerical variables. Each column can be categorized into one of the two variables types:

-   <u>Factor Variables:</u> `r paste(factor_cols, collapse=", ")`
-   <u>Numerical Variables:</u> `r paste(num_cols, collapse=", ")`

Additionally, *Figure 1* dispalys that this dataset doesn't contain any missing values. Therefore, any missing information imputation strategies won't be required during the data (pre)processing step of our analysis.

**Figure 1:** Counts of all the Missing Data per Column

```{r}
#| label: Missing data counts per column 
sapply(train_data, function(x) sum(is.na(x)))
```

An important thing to note is that despite the insights given by running the `str()` command, reading the column descriptions file gives contradicting information. For instance out of the `r sum(sapply(train_data, is.numeric))` numeric columns, only `age`, `absences` and `score` are 'true' numericcal variables. The rest of the variables are ordinal variables such as `Dalc`, a variable ranging from 1-5 based on workday alcohol consumption. This assessment is further backed up by analysing the top and bottom of the dataset as shown below in *Table 2* and *Table 3*:

**Table 2:** Top of the Dataset

```{r}
#| label: Top of the Dataset 
head(train_data)
```

**Table 3:** Bottom of the Dataset

```{r}
#| label: Bottom of the Dataset 
tail(train_data)
```

### The Analysis for the Dependent Variable: Score

```{r}
#| label: 5-number summary for score
minimum_value <- round(min(train_data$score), 2)
maximum_value <- round(max(train_data$score), 2)
median_value <- round(median(train_data$score), 2)
q1_value <- round(quantile(train_data$score, 0.25), 2)
q3_value <- round(quantile(train_data$score, 0.75), 2)
```

The whole aim of this analysis is to predict scores for students in the test dataset. In order to do so we took a closer look at the variable `score`. Below, *Figure 2* displays the spread of `score` in addition to a 5-number summary. Following the inter-quartile range rule for outlier detection, scores outside the range of $`r q1_value-1.5*(q3_value-q1_value)`\leq x \leq `r q3_value+1.5*(q3_value-q1_value)`$ would be considered outliers.

**Figure 2:** The Spread and 5-Number Summary of `score`

```{r}
#| label: Spread and summary statistics of score
# I made 3 graphs. Either pick one or multiple or make a new one!!!
train_data |> ggplot(aes(x=score)) +
  geom_histogram(fill = "skyblue", breaks = pretty(train_data$score, n=50)) + 
  geom_vline(xintercept = minimum_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Minimum =", minimum_value), color = "black", angle = 90, x = minimum_value-0.1, y = 19, size = 3) +
  geom_vline(xintercept = maximum_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Maximum =", maximum_value), color = "black", angle = 90, x = maximum_value-0.1, y = 19, size = 3) +
  geom_vline(xintercept = median_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Median =", median_value), color = "black", angle = 90, x = median_value-0.1, y = 19, size = 3) +
  geom_vline(xintercept = q1_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Quartile 1 =", q1_value), color = "black", angle = 90, x = q1_value-0.1, y = 19, size = 3) +
  geom_vline(xintercept = q3_value, colour = "black", linetype = "longdash") + 
  annotate(geom = "text", label = paste("Quartile 3 =", q3_value), color = "black", angle = 90, x = q3_value-0.1, y = 19, size = 3) 
```

```{r}
ggplot(train_data, aes(x = score)) +
  geom_density(fill = "skyblue") +
  xlab("Scores") +
  ylab("Frequency") +
  ggtitle("Density Plot of Scores with 5-Number Summary Overlay") +
  theme(plot.title = element_text(hjust = 0.5)) +
  
  geom_vline(aes(xintercept = minimum_value, color = "Minimum"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Minimum =", minimum_value), color = "black", angle = 90, x = minimum_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = maximum_value, color = "Maximum"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Maximum =", maximum_value), color = "black", angle = 90, x = maximum_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = median_value, color = "Median"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Median =", median_value), color = "black", angle = 90, x = median_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = q1_value, color = "Quartile 1"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Quartile 1 =", q1_value), color = "black", angle = 90, x = q1_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = q3_value, color = "Quartile 3"), linetype = "longdash") + 
  annotate(geom = "text", label = paste("Quartile 3 =", q3_value), color = "black", angle = 90, x = q3_value-0.1, y = 0.2, size = 3)
  

```

```{r}
ggplot(train_data, aes(x = score)) +
  geom_density(fill = "skyblue") +
  xlab("Scores") +
  ylab("Frequency") +
  ggtitle("Density Plot of Scores with 5-Number Summary Overlay") +
  theme(plot.title = element_text(hjust = 0.5)) +
  
  geom_vline(aes(xintercept = minimum_value, color = "Minimum = -2.71"), linetype = "longdash") + 
  annotate(geom = "text", label = "Minimum", color = "black", angle = 90, x = minimum_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = maximum_value, color = "Maximum = 2.23"), linetype = "longdash") + 
  annotate(geom = "text", label = "Maximum", color = "black", angle = 90, x = maximum_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = median_value, color = "Median = -0.03"), linetype = "longdash") + 
  annotate(geom = "text", label = "Median", color = "black", angle = 90, x = median_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = q1_value, color = "Quartile 1 = -0.63"), linetype = "longdash") + 
  annotate(geom = "text", label = "Quartile 1", color = "black", angle = 90, x = q1_value-0.1, y = 0.2, size = 3) +
  
  geom_vline(aes(xintercept = q3_value, color = "Quartile 3 = 0.64"), linetype = "longdash") + 
  annotate(geom = "text", label = "Quartile 3", color = "black", angle = 90, x = q3_value-0.1, y = 0.2, size = 3) +
  
  scale_color_manual("5-Number Summary", values = c("Minimum = -2.71" = "black", "Maximum = 2.23" = "black", "Median = -0.03" = "black", "Quartile 1 = -0.63" = "black", "Quartile 3 = 0.64" = "black"))

```

### Correlation between Score and the Explanatory Variables

For the correlation between `score` and the rest of the explanatory variables we divided the training dataset by variable type. *Table 4* displays the correlation between the numerical variables. The variables `failures`, `goout` and `age` measuring the student's number of past class failures, time spent with friend and age seemed to have the greatest negative correlation against `score` while `Medu` and `Fedu`, variables measuring their parent's education seemed to have the greatest positive correlation. Additionally, `goout` and `Dalc` (workday alcohol consumption) are both positively correlated with `Walc` (weekend alcohol consumption). In contrast, *Table 5* displays the correlation between the converted dummy categorical variables and `score`. Although, none of the categorical variables seemed to be correlated with `score`. The only strongly correlated variables in this table were between the categories of `Mjob` and `Fjob` (variables that measure the parent's occupation).

**Note:** Do we remove the correlated variables for the analysis and models?

**Table 4:** Correlation Matrix between Numerical Variables and `score`

```{r, fig.width = 10, fig.height = 10}
#| label: Correlation between numerical variables and score
corrplot(cor(train_data[sapply(train_data, is.numeric)]), diag = FALSE)
```

**Table 5:** Correlation Matrix between Converted Categorical Variables and `score`

```{r, fig.width = 10, fig.height = 10}
#| label: Correlation between dummy categorical variables and score
temp_df <- train_data[, !sapply(train_data, is.numeric)]
temp_df_dummy <- dummy_cols(temp_df,remove_first_dummy=TRUE,remove_selected_columns=TRUE)
temp_df_dummy$score <- train_data$score

corrplot(cor(temp_df_dummy), diag = FALSE)
```

## Data Preparation

### Data Cleaning

We have taken no data cleaning measures

### Data Transformation

We have taken a single tranformation measure, which is dummy coding the categorical attributes

```{r}
# dummy coding
train_dummy <- dummy_cols(train_data, remove_selected_columns = TRUE)
```

### Data reduction

We have taken no data reduction measures

## Model Training

### Creating Train/dev splits

Single train/dev split

```{r}
# creating a single train/dev split with a random 80/20 split
sample_size <- floor(0.8 * nrow(train_dummy))

set.seed(1)
train_index <- sample(seq_len(nrow(train_dummy)), size=sample_size)

train_dummy_train <- train_dummy[train_index,]
train_dummy_dev <- train_dummy[-train_index,]
```

k-fold cross validation

```{r}
# k-fold cross validation, k=5
train_control <- trainControl(method="cv", number=5)
```

### Training different models

#### Trivial baseline (mean)

We have chosen to create a trivial baseline by taking the mean score of the train data as the score for the dev data. So we are able to evaluate if our models perform better than this baseline.

```{r}
# creating a mean trivial baseline is not possible with the caret package
# the mean trivial baseline will be created with a single train/dev split

mean_score_train <- mean(train_dummy_train$score)
```

#### Linear regression

Another model we consider is the linear regression model, which we have applied to our k-fold cross validation.

```{r}
# training a linear model using k-fold crossvalidation
lm <- train(score ~ ., data=train_dummy, method="lm", trControl=train_control)
```

#### Neural Network

Another model we consider is the neural network model, which we have applied to our k-fold cross validation.

```{r}
# training a model averaged neural network using k-fold crossvalidation
nn <- train(score ~ ., data=train_dummy, method="avNNet", trControl=train_control)
```

#### kNN

Another model we consider is the k Nearest Neighbours model, which we have applied to our k-fold cross validation.

```{r}
# training knn using k-fold crossvalidation
knn <- train(score ~ ., data=train_dummy, method="knn", trControl=train_control)
```

## Model Evaluation

#### Trivial baseline (mean)

The trivial baseline is evaluated by calculating the MAE and the MSE

```{r}
# resulting MAE and MSE from the trivial baseline
mae <- mean(abs(train_dummy_dev$score - mean_score_train))
mse <- mean((train_dummy_dev$score - mean_score_train) ** 2)

print(mae)
print(mse)
```

#### Linear Regression

The linear regression model is evaluated with RMSE, Rsquared, and MAE

```{r}
# resulting scores (including MAE) from linear regression
print(lm)
```

#### Neural Network

The neural network model is evaluated with RMSE, Rsquared, and MAE

```{r}
print(nn)
```

#### kNN

The kNN model is evaluated with RMSE, Rsquared, and MAE

```{r}
print(knn)
```

#### Chosen Model

*Current best is kNN, but this might change with later updates. Will leave it for now*.

## Result

*Apply the chosen model to predict the scores for the test data and export the result*

## Team member contributions

-   Lourenço Santos Moitinho de Almeida: Data Description & Data Exploration
-   Liam Thomassen: b, c, d
-   Tim Rentenaar: Data Preparation, Model Training, Model Evaluation
-   Erdem Koçer: a, b, d
